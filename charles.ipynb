{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charles Book Club - predict customers who will buy a certain book\n",
    "\n",
    "Given customer data, we have to predict if the customer is likely to buy a book 'The Art History of Florence.' As the data is highly skewed with 10 percent positive samples and 90 percent negative samples instead of using accuracy as a parameter we are more concerened with the RECALL of the model. If the recall(ratio of predicted true positives over all positives) is high, we are less likely to miss a customer for advertising the new book. Therefore the model aims at improving recall of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score,precision_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CBC_4000.csv',header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq#</th>\n",
       "      <th>ID#</th>\n",
       "      <th>Gender</th>\n",
       "      <th>M</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>FirstPurch</th>\n",
       "      <th>ChildBks</th>\n",
       "      <th>YouthBks</th>\n",
       "      <th>CookBks</th>\n",
       "      <th>...</th>\n",
       "      <th>Related Purchase</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Mcode</th>\n",
       "      <th>Rcode</th>\n",
       "      <th>Fcode</th>\n",
       "      <th>Yes_Florence</th>\n",
       "      <th>No_Florence</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>257</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seq#  ID#  Gender    M   R  F  FirstPurch  ChildBks  YouthBks  CookBks  \\\n",
       "0     1   25       1  297  14  2          22         0         1        1   \n",
       "1     2   29       0  128   8  2          10         0         0        0   \n",
       "2     3   46       1  138  22  7          56         2         1        2   \n",
       "3     4   47       1  228   2  1           2         0         0        0   \n",
       "4     5   51       1  257  10  1          10         0         0        0   \n",
       "\n",
       "      ...       Related Purchase  Unnamed: 19  Mcode  Rcode  Fcode  \\\n",
       "0     ...                      0          NaN      5      4      2   \n",
       "1     ...                      0          NaN      4      3      2   \n",
       "2     ...                      2          NaN      4      4      3   \n",
       "3     ...                      0          NaN      5      1      1   \n",
       "4     ...                      0          NaN      5      3      1   \n",
       "\n",
       "   Yes_Florence  No_Florence  Unnamed: 25  Unnamed: 26  Unnamed: 27  \n",
       "0             0            1          NaN          NaN          NaN  \n",
       "1             0            1          NaN          NaN          NaN  \n",
       "2             0            1          NaN          NaN          NaN  \n",
       "3             0            1          NaN          NaN          NaN  \n",
       "4             0            1          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Seq#', 'ID#', 'Gender', 'M', 'R', 'F', 'FirstPurch', 'ChildBks',\n",
       "       'YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks',\n",
       "       'ItalCook', 'ItalAtlas', 'ItalArt', 'Florence', 'Related Purchase',\n",
       "       'Unnamed: 19', 'Mcode', 'Rcode', 'Fcode', 'Yes_Florence', 'No_Florence',\n",
       "       'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only the required columns and performing regularisation on columns with large values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['Gender', 'M', 'R', 'F', 'FirstPurch', 'ChildBks',\n",
    "       'YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks',\n",
    "       'ItalCook', 'ItalAtlas', 'ItalArt', 'Florence', 'Related Purchase']]\n",
    "for col in ['M', 'R', 'F', 'FirstPurch']:\n",
    "    df[col] = (df[col] - df[col].mean())/df[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>M</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>FirstPurch</th>\n",
       "      <th>ChildBks</th>\n",
       "      <th>YouthBks</th>\n",
       "      <th>CookBks</th>\n",
       "      <th>DoItYBks</th>\n",
       "      <th>RefBks</th>\n",
       "      <th>ArtBks</th>\n",
       "      <th>GeogBks</th>\n",
       "      <th>ItalCook</th>\n",
       "      <th>ItalAtlas</th>\n",
       "      <th>ItalArt</th>\n",
       "      <th>Florence</th>\n",
       "      <th>Related Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.880731</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>-0.530088</td>\n",
       "      <td>-0.245608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.793389</td>\n",
       "      <td>-0.665180</td>\n",
       "      <td>-0.530088</td>\n",
       "      <td>-0.899510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.694329</td>\n",
       "      <td>1.062400</td>\n",
       "      <td>0.915673</td>\n",
       "      <td>1.607113</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.197214</td>\n",
       "      <td>-1.405571</td>\n",
       "      <td>-0.819241</td>\n",
       "      <td>-1.335445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.484489</td>\n",
       "      <td>-0.418383</td>\n",
       "      <td>-0.819241</td>\n",
       "      <td>-0.899510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender         M         R         F  FirstPurch  ChildBks  YouthBks  \\\n",
       "0       1  0.880731  0.075211 -0.530088   -0.245608         0         1   \n",
       "1       0 -0.793389 -0.665180 -0.530088   -0.899510         0         0   \n",
       "2       1 -0.694329  1.062400  0.915673    1.607113         2         1   \n",
       "3       1  0.197214 -1.405571 -0.819241   -1.335445         0         0   \n",
       "4       1  0.484489 -0.418383 -0.819241   -0.899510         0         0   \n",
       "\n",
       "   CookBks  DoItYBks  RefBks  ArtBks  GeogBks  ItalCook  ItalAtlas  ItalArt  \\\n",
       "0        1         0       0       0        0         0          0        0   \n",
       "1        0         0       0       0        0         0          0        0   \n",
       "2        2         0       1       0        1         1          0        0   \n",
       "3        0         0       0       0        0         0          0        0   \n",
       "4        0         0       0       0        0         0          0        0   \n",
       "\n",
       "   Florence  Related Purchase  \n",
       "0         0                 0  \n",
       "1         0                 0  \n",
       "2         0                 2  \n",
       "3         0                 0  \n",
       "4         0                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataframe into features X and target variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[['Gender', 'M', 'R', 'F', 'FirstPurch', 'ChildBks',\n",
    "       'YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks',\n",
    "       'ItalCook', 'ItalAtlas', 'ItalArt', 'Related Purchase']]\n",
    "y = df['Florence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3662\n",
       "1     338\n",
       "Name: Florence, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the dataset is highly unbalanced. Anyway ignoring this for the time being and splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2551\n",
       "1     249\n",
       "Name: Florence, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data is highly unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying logistic regression on unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9275\n",
      "validation loss:  2.50406128863\n",
      "training loss:  2.98513767384\n",
      "confusion matrix:\n",
      "  [[1111    0]\n",
      " [  87    2]]\n",
      "test f1 score:  0.043956043956\n",
      "recall:  0.0224719101124\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('accuracy: ', accuracy_score(predictions,y_test))\n",
    "#a = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "#print('training ',a)\n",
    "#a = precision_recall_fscore_support(y_val,predictions)\n",
    "#print('val ',a)\n",
    "print('validation loss: ' ,log_loss(y_test,predictions))\n",
    "print('training loss: ', log_loss(y_train,y_train_pred))\n",
    "print('confusion matrix:\\n ', confusion_matrix(y_test, predictions))\n",
    "print('test f1 score: ', f1_score(y_test,predictions))\n",
    "#print(f1_score(y_train,y_train_pred))\n",
    "print('recall: ',recall_score(y_test,predictions))\n",
    "print('precision: ',precision_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is high but that is not the right metric to judge our model as the data is highly skewed. We want high recall which is really poor in this case. Let us try using 'balanced logistic regression' which adjusts the weights of our model according to the frequency of each class. Also we are varying the C parameter for regularisation.(increasing variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6575\n",
      "validation loss:  11.8297734598\n",
      "training loss:  11.4473694883\n",
      "confusion matrix:\n",
      "  [[747 364]\n",
      " [ 47  42]]\n",
      "test f1 score:  0.169696969697\n",
      "recall:  0.47191011236\n",
      "precision:  0.103448275862\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight = 'balanced', C=100)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('accuracy: ', accuracy_score(predictions,y_test))\n",
    "#a = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "#print('training ',a)\n",
    "#a = precision_recall_fscore_support(y_val,predictions)\n",
    "#print('val ',a)\n",
    "print('validation loss: ' ,log_loss(y_test,predictions))\n",
    "print('training loss: ', log_loss(y_train,y_train_pred))\n",
    "print('confusion matrix:\\n ', confusion_matrix(y_test, predictions))\n",
    "print('test f1 score: ', f1_score(y_test,predictions))\n",
    "#print(f1_score(y_train,y_train_pred))\n",
    "print('recall: ',recall_score(y_test,predictions))\n",
    "print('precision: ',precision_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an okayish recall this time. Hence we should now try something else to reduce this problem of skewed classes in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SMOTE(synthetic minority oversampling technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct way of applying SMOTE is to apply it to the training set only not to the entire dataset. This will ensure that similar examples are not copied over to the test set giving us false high results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 1,ratio = 'minority')\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "y_train_res = pd.Series(y_train_res)\n",
    "X_train_res = pd.DataFrame(X_train_res)\n",
    "X_train_res.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can now see the two classes are balanced in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2339\n",
       "0    2339\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_res).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying logistic regression again, this time to the training set with balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.664166666667\n",
      "validation loss:  11.5995142842\n",
      "training loss:  13.1420566882\n",
      "confusion matrix:\n",
      "  [[748 363]\n",
      " [ 40  49]]\n",
      "test f1 score:  0.195608782435\n",
      "recall:  0.550561797753\n",
      "precision:  0.118932038835\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C = 100)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "predictions = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train_res)\n",
    "print('accuracy: ', accuracy_score(predictions,y_test))\n",
    "#a = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "#print('training ',a)\n",
    "#a = precision_recall_fscore_support(y_val,predictions)\n",
    "#print('val ',a)\n",
    "print('validation loss: ' ,log_loss(y_test,predictions))\n",
    "print('training loss: ', log_loss(y_train_res,y_train_pred))\n",
    "print('confusion matrix:\\n ', confusion_matrix(y_test, predictions))\n",
    "print('test f1 score: ', f1_score(y_test,predictions))\n",
    "#print(f1_score(y_train,y_train_pred))\n",
    "print('recall: ',recall_score(y_test,predictions))\n",
    "print('precision: ',precision_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the recall has improved a bit. Let us now try some other model. Also using K-Fold validation this time with 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time for SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using K FOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KFold with 5 folds, applying SMOTE on 4 folds and using the remaining fold as test set. We use an 'rbf' kernel with parameters C =500, and gamma = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JCV:  0.755553224832\n",
      "Jtrain: 0.590617785861\n",
      "recall:  1.0\n",
      "accuracy:  0.978125\n",
      "[[571  14]\n",
      " [  0  55]]\n",
      "\n",
      "\n",
      "JCV:  1.83490497963\n",
      "Jtrain: 0.602018585662\n",
      "recall:  0.854545454545\n",
      "accuracy:  0.946875\n",
      "[[559  26]\n",
      " [  8  47]]\n",
      "\n",
      "\n",
      "JCV:  1.67299946779\n",
      "Jtrain: 0.48381039307\n",
      "recall:  0.836363636364\n",
      "accuracy:  0.9515625\n",
      "[[563  22]\n",
      " [  9  46]]\n",
      "\n",
      "\n",
      "JCV:  1.942832409\n",
      "Jtrain: 0.558413568778\n",
      "recall:  0.727272727273\n",
      "accuracy:  0.94375\n",
      "[[564  21]\n",
      " [ 15  40]]\n",
      "\n",
      "\n",
      "JCV:  1.99680049649\n",
      "Jtrain: 0.571142120852\n",
      "recall:  0.727272727273\n",
      "accuracy:  0.9421875\n",
      "[[563  22]\n",
      " [ 15  40]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_split = X.iloc[train_index]\n",
    "    y_train_split = y[train_index]\n",
    "    \n",
    "    X_test_split = X.iloc[test_index]\n",
    "    y_test_split = y[test_index]\n",
    "        \n",
    "    sm = SMOTE(random_state = 1,ratio = 'minority')\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_split, y_train_split)\n",
    "    y_train_res = pd.Series(y_train_res)\n",
    "    X_train_res = pd.DataFrame(X_train_res)\n",
    "    X_train_res.columns = X_train.columns\n",
    "    \n",
    "    model = svm.SVC(kernel='rbf',C=500, gamma = 2)\n",
    "    \n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    predictions = model.predict(X_val)\n",
    "    y_train_res_pred = model.predict(X_train_res)\n",
    "    recall_list.append(recall_score(y_val,predictions))\n",
    "    \n",
    "    print('JCV: ',log_loss(y_val,predictions))\n",
    "    print('Jtrain:', log_loss(y_train_res,y_train_res_pred))\n",
    "    print('recall: ',recall_score(y_val,predictions))\n",
    "    print('accuracy: ',accuracy_score(y_val,predictions))\n",
    "    print(confusion_matrix(y_val, predictions))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  0.829090909091\n"
     ]
    }
   ],
   "source": [
    "print('recall: ',sum(recall_list)/len(recall_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore by using Smote with cross validation and an SVM model we have increased the recall to 82.9 percent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
